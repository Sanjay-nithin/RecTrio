{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa25d9a",
   "metadata": {},
   "source": [
    "# Zero-Shot CLIP Inference with OpenVINO\n",
    "\n",
    "This notebook performs image and text-based search using zero-shot CLIP model optimized with OpenVINO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f13ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from openvino.runtime import Core\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e8c5ca",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49343731",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(r\"e:\\Projects\\AI Based\\RecTrio\\V2\\models\")\n",
    "VECTOR_DB_DIR = Path(r\"e:\\Projects\\AI Based\\RecTrio\\V2\\vector_db\")\n",
    "\n",
    "CLIP_MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "VISION_MODEL_PATH = MODEL_DIR / \"clip_vision_model.xml\"\n",
    "TEXT_MODEL_PATH = MODEL_DIR / \"clip_text_model.xml\"\n",
    "FAISS_INDEX_PATH = VECTOR_DB_DIR / \"faiss_index.bin\"\n",
    "METADATA_PATH = VECTOR_DB_DIR / \"metadata.pkl\"\n",
    "\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb127214",
   "metadata": {},
   "source": [
    "## Load Processor and Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93114c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CLIP processor...\")\n",
    "processor = CLIPProcessor.from_pretrained(CLIP_MODEL_NAME)\n",
    "\n",
    "print(\"Loading CLIP model for projections...\")\n",
    "model = CLIPModel.from_pretrained(CLIP_MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "visual_projection = model.visual_projection.weight.detach().numpy().T\n",
    "text_projection = model.text_projection.weight.detach().numpy().T\n",
    "\n",
    "print(\"Processor and projections loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09366e2",
   "metadata": {},
   "source": [
    "## Load OpenVINO Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ae456",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Core()\n",
    "\n",
    "print(\"Loading vision model...\")\n",
    "vision_compiled_model = core.compile_model(str(VISION_MODEL_PATH), \"CPU\")\n",
    "vision_input_layer = vision_compiled_model.input(0)\n",
    "vision_output_layer = vision_compiled_model.output(0)\n",
    "\n",
    "print(\"Loading text model...\")\n",
    "text_compiled_model = core.compile_model(str(TEXT_MODEL_PATH), \"CPU\")\n",
    "text_output_layer = text_compiled_model.output(0)\n",
    "\n",
    "print(\"OpenVINO models loaded on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affccdbd",
   "metadata": {},
   "source": [
    "## Load FAISS Index and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dcb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading FAISS index...\")\n",
    "index = faiss.read_index(str(FAISS_INDEX_PATH))\n",
    "print(f\"Loaded index with {index.ntotal} vectors\")\n",
    "\n",
    "print(\"Loading metadata...\")\n",
    "with open(METADATA_PATH, 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "image_paths = metadata['image_paths']\n",
    "print(f\"Loaded {len(image_paths)} image paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbc6ae",
   "metadata": {},
   "source": [
    "## Embedding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image_input):\n",
    "    if isinstance(image_input, str):\n",
    "        image = Image.open(image_input).convert('RGB')\n",
    "    else:\n",
    "        image = image_input.convert('RGB')\n",
    "    \n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    pixel_values = inputs['pixel_values'].numpy()\n",
    "    \n",
    "    result = vision_compiled_model([pixel_values])[vision_output_layer]\n",
    "    pooled_output = result[0]\n",
    "    \n",
    "    embedding = np.dot(pooled_output, visual_projection)\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    \n",
    "    return embedding.astype('float32')\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    inputs = processor(text=[text], return_tensors=\"pt\", padding=True)\n",
    "    input_ids = inputs['input_ids'].numpy()\n",
    "    attention_mask = inputs['attention_mask'].numpy()\n",
    "    \n",
    "    result = text_compiled_model({'input_ids': input_ids, 'attention_mask': attention_mask})[text_output_layer]\n",
    "    pooled_output = result[0]\n",
    "    \n",
    "    embedding = np.dot(pooled_output, text_projection)\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    \n",
    "    return embedding.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64dd880",
   "metadata": {},
   "source": [
    "## Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a85eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_images(query_embedding, top_k=TOP_K):\n",
    "    query_embedding = query_embedding.reshape(1, -1)\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        results.append({\n",
    "            'path': image_paths[idx],\n",
    "            'similarity': float(dist)\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce72e4a",
   "metadata": {},
   "source": [
    "## Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results, query_info=None):\n",
    "    n_results = len(results)\n",
    "    cols = 5\n",
    "    rows = (n_results + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    axes = axes.flatten() if n_results > 1 else [axes]\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        img = Image.open(result['path'])\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f\"Similarity: {result['similarity']:.4f}\", fontsize=10)\n",
    "    \n",
    "    for idx in range(n_results, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    if query_info:\n",
    "        fig.suptitle(f\"Query: {query_info}\", fontsize=14, y=1.00)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235b976",
   "metadata": {},
   "source": [
    "## Image-Based Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291660ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_image_path = r\"e:\\Projects\\AI Based\\RecTrio\\V1\\datasets\\animals\\raw-img\\cat\\1.jpeg\"\n",
    "\n",
    "print(f\"Searching for images similar to: {query_image_path}\")\n",
    "query_embedding = get_image_embedding(query_image_path)\n",
    "results = search_similar_images(query_embedding)\n",
    "\n",
    "print(f\"\\nTop {len(results)} similar images:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['path']} (Similarity: {result['similarity']:.4f})\")\n",
    "\n",
    "display_results(results, query_info=f\"Image: {Path(query_image_path).name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce7917",
   "metadata": {},
   "source": [
    "## Text-Based Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"a photo of a cat\"\n",
    "\n",
    "print(f\"Searching for: '{query_text}'\")\n",
    "query_embedding = get_text_embedding(query_text)\n",
    "results = search_similar_images(query_embedding)\n",
    "\n",
    "print(f\"\\nTop {len(results)} similar images:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['path']} (Similarity: {result['similarity']:.4f})\")\n",
    "\n",
    "display_results(results, query_info=f\"Text: '{query_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879e37e",
   "metadata": {},
   "source": [
    "## Interactive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_search():\n",
    "    print(\"Choose search type:\")\n",
    "    print(\"1. Image search\")\n",
    "    print(\"2. Text search\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        image_path = input(\"Enter image path: \").strip()\n",
    "        if not os.path.exists(image_path):\n",
    "            print(\"Image not found!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nSearching for images similar to: {image_path}\")\n",
    "        query_embedding = get_image_embedding(image_path)\n",
    "        results = search_similar_images(query_embedding)\n",
    "        \n",
    "        print(f\"\\nTop {len(results)} similar images:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"{i}. {result['path']} (Similarity: {result['similarity']:.4f})\")\n",
    "        \n",
    "        display_results(results, query_info=f\"Image: {Path(image_path).name}\")\n",
    "        \n",
    "    elif choice == \"2\":\n",
    "        text_query = input(\"Enter search text: \").strip()\n",
    "        \n",
    "        print(f\"\\nSearching for: '{text_query}'\")\n",
    "        query_embedding = get_text_embedding(text_query)\n",
    "        results = search_similar_images(query_embedding)\n",
    "        \n",
    "        print(f\"\\nTop {len(results)} similar images:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"{i}. {result['path']} (Similarity: {result['similarity']:.4f})\")\n",
    "        \n",
    "        display_results(results, query_info=f\"Text: '{text_query}'\")\n",
    "    else:\n",
    "        print(\"Invalid choice!\")\n",
    "\n",
    "interactive_search()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
