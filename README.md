# RecTrio - Image Similarity & Recommendation System

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive image similarity and recommendation system using **Triplet Networks**. This repository contains two distinct implementations demonstrating different approaches to metric learning:

1. **Fashion MNIST**: Training a triplet network **from scratch**
2. **Animals Dataset**: Fine-tuning a **pretrained CLIP model** using triplet networks

---

## ğŸ“š Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Technical Approach](#technical-approach)
- [Full-Stack Application Roadmap](#full-stack-application-roadmap)
- [Free Infrastructure Options](#free-infrastructure-options)
- [Quick Start](#quick-start)
- [Training on Google Colab](#training-on-google-colab)
- [Deployment Guide](#deployment-guide)

---

## ğŸ¯ Overview

### What is RecTrio?

RecTrio is an AI-powered image similarity search and recommendation system that learns to understand visual similarity using triplet networks. It can find visually similar images, recommend products, and power reverse image search applications.

### Two Implementations Explained

#### 1ï¸âƒ£ **Fashion MNIST - Training from Scratch**

**Dataset**: Fashion MNIST (70,000 grayscale images of 10 fashion categories)

**Approach**:
- âœ… Custom CNN architecture built from scratch
- âœ… Trained on triplets: (anchor, positive, negative)
- âœ… Learns embeddings in a 128-dimensional space
- âœ… Uses triplet margin loss for metric learning
- âœ… No pretrained models - learns everything from the dataset

**Use Case**: Demonstrates fundamental triplet learning concepts on a simple dataset

**Files**: `FashionMNIST/main.ipynb`, `FashionMNIST/fashion_mnist_visualization.ipynb`

**Key Features**:
- Simple CNN: Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ FC layers
- Embedding dimension: 128
- Training time: ~15-20 minutes on GPU
- Perfect for learning and experimentation

---

#### 2ï¸âƒ£ **Animals Dataset - Fine-tuning CLIP**

**Dataset**: 10 animal classes with RGB images (variable sizes)

**Approach**:
- âœ… Leverages **CLIP** (Contrastive Language-Image Pre-training) from OpenAI
- âœ… CLIP is pretrained on 400M image-text pairs from the internet
- âœ… Two-phase fine-tuning strategy:
  - **Phase 1**: Train projection head only (CLIP frozen)
  - **Phase 2**: Fine-tune last transformer layers + projection head
- âœ… Adapts powerful visual representations to our specific task
- âœ… Uses FAISS for efficient similarity search at scale

**Use Case**: Production-ready system for real-world image search applications

**Files**: `Animals/*.py`, `Animals/train_colab.ipynb`

**Key Features**:
- CLIP ViT-B/32 encoder (87M parameters)
- Projection head reduces 512D â†’ 128D
- FAISS HNSW index for fast nearest neighbor search
- Handles high-resolution images
- Scalable to millions of images

---

## ğŸ“‚ Project Structure

```
RecTrio/
â”‚
â”œâ”€â”€ FashionMNIST/                      # Project 1: From-scratch training
â”‚   â”œâ”€â”€ main.ipynb                     # Complete training notebook
â”‚   â”œâ”€â”€ fashion_mnist_visualization.ipynb
â”‚   â”œâ”€â”€ best_triplet_model.pth         # Trained model weights
â”‚   â””â”€â”€ archive (1)/                   # Dataset (auto-downloaded)
â”‚       â””â”€â”€ fashion-mnist_*.csv
â”‚
â”œâ”€â”€ Animals/                           # Project 2: CLIP fine-tuning
â”‚   â”œâ”€â”€ config.py                      # Configuration & hyperparameters
â”‚   â”œâ”€â”€ dataset.py                     # Triplet dataset loader
â”‚   â”œâ”€â”€ model.py                       # CLIP + projection head
â”‚   â”œâ”€â”€ train.py                       # Two-phase training pipeline
â”‚   â”œâ”€â”€ build_index.py                 # FAISS index builder
â”‚   â”œâ”€â”€ search.py                      # Similarity search engine
â”‚   â”œâ”€â”€ visualize_results.py           # Result visualization
â”‚   â”œâ”€â”€ main.py                        # CLI interface
â”‚   â”œâ”€â”€ train_colab.ipynb              # Google Colab training notebook
â”‚   â”œâ”€â”€ utils.py                       # Helper functions
â”‚   â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ checkpoints/               # Model checkpoints
â”‚       â”‚   â”œâ”€â”€ best_triplet_model.pth
â”‚       â”‚   â””â”€â”€ last_triplet_model.pth
â”‚       â””â”€â”€ faiss_index/               # Vector database
â”‚           â”œâ”€â”€ image_embeddings.index
â”‚           â””â”€â”€ image_paths.pkl
â”‚
â””â”€â”€ requirements.txt                   # Global dependencies
```

---

## ğŸ”¬ Technical Approach

### Triplet Learning Fundamentals

Both projects use **triplet loss** for metric learning:

```
Loss = max(0, ||anchor - positive||Â² - ||anchor - negative||Â² + margin)
```

**Goal**: 
- Minimize distance between similar images (anchor & positive)
- Maximize distance between dissimilar images (anchor & negative)
- Maintain a safety margin between the two distances

### Architecture Comparison

| Aspect | Fashion MNIST | Animals (CLIP) |
|--------|---------------|----------------|
| **Input** | 28Ã—28 grayscale | 224Ã—224 RGB |
| **Base Model** | Custom CNN | Pretrained CLIP ViT-B/32 |
| **Encoder Params** | ~500K | 87M (pretrained) |
| **Training Strategy** | End-to-end from scratch | Two-phase fine-tuning |
| **Embedding Dim** | 128 | 512 â†’ 128 (projection) |
| **Training Time** | 15-20 min | 2-3 hours |
| **Scalability** | Limited (simple dataset) | Production-ready |
| **Search Method** | Brute force | FAISS HNSW index |

### Why CLIP for Animals Dataset?

1. **Transfer Learning**: CLIP has seen millions of diverse images during pretraining
2. **Rich Features**: Understands complex visual concepts (textures, shapes, contexts)
3. **Faster Convergence**: Pretrained weights mean less training time
4. **Better Generalization**: Works well even with limited training data
5. **Multimodal**: Can be extended to text-image search

---

## ğŸ—ï¸ Full-Stack Application Roadmap

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CLIENT LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web App (React/Next.js) â”‚ Mobile App (React Native)        â”‚
â”‚  - Image Upload UI        â”‚ - Camera Integration             â”‚
â”‚  - Search Results Grid    â”‚ - Similar Product Feed           â”‚
â”‚  - Filters & Sorting      â”‚ - Saved Searches                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“ HTTPS/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API GATEWAY LAYER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FastAPI / Flask Backend (Python)                           â”‚
â”‚  - /upload - Image upload endpoint                          â”‚
â”‚  - /search - Similarity search endpoint                     â”‚
â”‚  - /recommend - Recommendation endpoint                     â”‚
â”‚  - Authentication & Rate Limiting                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ML INFERENCE LAYER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Model Server (TorchServe / Custom)                         â”‚
â”‚  - Load trained CLIP model                                  â”‚
â”‚  - Generate 128D embeddings                                 â”‚
â”‚  - Batch processing support                                 â”‚
â”‚  - GPU acceleration                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VECTOR DATABASE LAYER                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FAISS / Pinecone / Qdrant / Weaviate                       â”‚
â”‚  - Store image embeddings (128D vectors)                    â”‚
â”‚  - Fast nearest neighbor search                             â”‚
â”‚  - Filter by metadata (category, price, etc.)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STORAGE & DATABASE LAYER                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Object Storage          â”‚  Metadata Database               â”‚
â”‚  - Cloudinary (Free)     â”‚  - PostgreSQL / MongoDB          â”‚
â”‚  - AWS S3 (Free tier)    â”‚  - Supabase (Free)               â”‚
â”‚  - Imgur API             â”‚  - Store image URLs, tags        â”‚
â”‚  - ImageKit.io           â”‚  - User data, search history     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° Free Infrastructure Options

### 1. **Image Storage (Free Tier)**

#### Option A: **Cloudinary** â­ Recommended
- **Free Tier**: 25GB storage, 25GB bandwidth/month
- **Features**: Auto-optimization, CDN, transformations
- **Pros**: Easy to use, excellent free tier, image transformations
- **Capacity**: ~25,000-50,000 images
- **API**: Simple REST API
```python
# Example
import cloudinary.uploader
result = cloudinary.uploader.upload("image.jpg")
url = result['secure_url']
```

### 2. **Vector Database for Embeddings**

#### Option A: **Pinecone** â­ Best for Production
- **Free Tier**: 
  - 1 pod (1M vectors, 100k queries/month)
  - 128-dimensional embeddings
  - Perfect for this project!
- **Features**: Managed service, auto-scaling, metadata filtering
- **Capacity**: ~1,000,000 images
```python
import pinecone
pinecone.init(api_key="YOUR_KEY")
index = pinecone.Index("image-search")
index.upsert(vectors=[("id1", embedding, {"url": "..."})])
```

#### Option B: **Qdrant Cloud**
- **Free Tier**: 1GB cluster (256 dimensional vectors)
- **Features**: Open source, good documentation
- **Capacity**: ~8,000,000 vectors (128D)

#### Option C: **Weaviate Cloud**
- **Free Tier**: 30-day trial, then limited free tier
- **Features**: GraphQL API, hybrid search
- **Capacity**: Varies

#### Option D: **Local FAISS** â­ Best for Development
- **Cost**: FREE (runs on your server)
- **Features**: Lightning fast, no API limits
- **Cons**: You manage infrastructure
- **Capacity**: Limited only by RAM/disk
- **Best for**: MVP, testing, small-scale deployments

### 3. **Compute & Hosting**

#### Model Inference:
- **Hugging Face Spaces** (Free): Host Gradio/Streamlit apps with GPU
- **Google Colab** (Free): Training and experimentation
- **Railway.app** (Free tier): Deploy Python backends
- **Render.com** (Free tier): 750 hours/month
- **Fly.io** (Free tier): Small containers

#### Backend API:
- **Vercel** (Free): Serverless functions (Node.js)
- **Railway.app** (Free): $5 credit/month
- **Render.com** (Free): Web services
- **Heroku** (Limited free): Dynos available

#### Frontend:
- **Vercel** (Free): Next.js hosting â­
- **Netlify** (Free): Static sites
- **GitHub Pages** (Free): Static sites

### 4. **Database for Metadata**

#### Option A: **Supabase** â­ Recommended
- **Free Tier**: 500MB database, 1GB file storage
- **Features**: PostgreSQL, real-time, auth, storage
- **Capacity**: 100,000+ records
```sql
CREATE TABLE images (
    id UUID PRIMARY KEY,
    url TEXT,
    embedding_id TEXT,
    category TEXT,
    tags TEXT[],
    created_at TIMESTAMP
);
```

#### Option B: **MongoDB Atlas**
- **Free Tier**: 512MB storage
- **Features**: NoSQL, flexible schema
- **Capacity**: 100,000+ documents

#### Option C: **PlanetScale**
- **Free Tier**: 5GB storage, 1 billion reads/month
- **Features**: MySQL-compatible, branching

---

## ğŸš€ Recommended Free Stack (0 Cost MVP)

### For ~100,000 Images:

| Component | Service | Free Tier |
|-----------|---------|-----------|
| **Image Storage** | Cloudinary | 25GB (~25k images) |
| **Vector DB** | Pinecone | 1M vectors |
| **Metadata DB** | Supabase | 500MB PostgreSQL |
| **Backend API** | Railway/Render | Free tier |
| **Model Hosting** | Hugging Face Spaces | GPU inference |
| **Frontend** | Vercel | Unlimited |
| **CDN** | Cloudinary/Cloudflare | Included |

**Total Monthly Cost**: $0 (within free tiers)

**Capacity**: 
- 25,000 images (Cloudinary limit)
- 1,000,000 searchable vectors (Pinecone limit)
- Unlimited searches (with reasonable rate limits)

---

## ğŸ’¡ Scaling Strategy

### For 1M+ Images:

| Users/Month | Images | Storage | Vector DB | Cost Estimate |
|-------------|--------|---------|-----------|---------------|
| <1K | <25K | Cloudinary Free | Pinecone Free | **$0** |
| 1K-10K | 25K-100K | Cloudinary $99 | Pinecone Free | **$99/mo** |
| 10K-100K | 100K-500K | S3 ~$10 | Pinecone $70 | **$80-150/mo** |
| 100K+ | 1M+ | S3 ~$50 | Qdrant/Custom | **$200-500/mo** |

---

## ğŸ› ï¸ Quick Start

### Prerequisites

```bash
# Python 3.8+
python --version

python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 1. Fashion MNIST (From Scratch)

```bash
cd FashionMNIST
jupyter notebook main.ipynb
# Run all cells to train and evaluate
```

---
