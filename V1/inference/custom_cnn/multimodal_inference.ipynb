{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "570733bb",
   "metadata": {},
   "source": [
    "# Multimodal Inference with Custom CNN + Text Encoder (Fashion MNIST)\n",
    "\n",
    "This notebook performs **image-based** and **text-based** search using your custom trained dual-encoder model on Fashion MNIST dataset.\n",
    "\n",
    "## Features:\n",
    "- Query by **image** → Get similar fashion items\n",
    "- Query by **text** → Get matching fashion items\n",
    "- Dataset: Fashion MNIST (10 fashion categories)\n",
    "- Intel CPU optimized with OpenVINO\n",
    "- FAISS-based fast similarity search\n",
    "- Grayscale image support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf8e74",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa89cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from openvino.runtime import Core\n",
    "import faiss\n",
    "\n",
    "# Add datasets path\n",
    "sys.path.append(r'e:\\Projects\\AI Based\\RecTrio\\datasets\\fashion_mnist')\n",
    "from V1.training.custom_cnn.text_descriptions import FASHION_DESCRIPTIONS, CLASSES\n",
    "\n",
    "print(\"✓ Libraries imported\")\n",
    "print(f\"  Fashion categories: {len(CLASSES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5250140",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429eda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "MODEL_DIR = Path(r'e:\\Projects\\AI Based\\RecTrio\\V1\\models\\fashion_cnn')\n",
    "DATASET_PATH = Path(r'e:\\Projects\\AI Based\\RecTrio\\datasets\\fashion_mnist\\processed\\train')\n",
    "VECTOR_DB_DIR = Path(r'e:\\Projects\\AI Based\\RecTrio\\V1\\models\\fashion_cnn\\vector_db')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VECTOR_DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model files\n",
    "IMAGE_ENCODER_PATH = MODEL_DIR / 'image_encoder.xml'\n",
    "TEXT_ENCODER_PATH = MODEL_DIR / 'text_encoder.xml'\n",
    "VOCAB_PATH = MODEL_DIR / 'vocabulary.pkl'\n",
    "\n",
    "# Vector database files\n",
    "EMBEDDINGS_FILE = VECTOR_DB_DIR / 'embeddings.npy'\n",
    "METADATA_FILE = VECTOR_DB_DIR / 'metadata.pkl'\n",
    "FAISS_INDEX_FILE = VECTOR_DB_DIR / 'faiss_index.bin'\n",
    "\n",
    "# Configuration from training\n",
    "IMAGE_SIZE = 224\n",
    "print(f\"✓ Model directory: {MODEL_DIR}\")\n",
    "print(f\"✓ Vector DB directory: {VECTOR_DB_DIR}\")\n",
    "\n",
    "print(f\"✓ All directories verified/created\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "print(f\"Vector DB directory: {VECTOR_DB_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6d323",
   "metadata": {},
   "source": [
    "## 3. Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc94ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading vocabulary...\")\n",
    "with open(VOCAB_PATH, 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Vocabulary loaded: {vocab.n_words} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f83e7",
   "metadata": {},
   "source": [
    "## 4. Load OpenVINO Models (Intel CPU Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing OpenVINO Runtime...\")\n",
    "core = Core()\n",
    "\n",
    "# Load image encoder\n",
    "print(\"Loading image encoder...\")\n",
    "image_model = core.compile_model(str(IMAGE_ENCODER_PATH), \"CPU\")\n",
    "image_input = image_model.input(0)\n",
    "image_output = image_model.output(0)\n",
    "print(f\"  Input shape: {image_input.partial_shape}\")\n",
    "print(f\"  Output shape: {image_output.partial_shape}\")\n",
    "\n",
    "# Load text encoder\n",
    "print(\"Loading text encoder...\")\n",
    "text_model = core.compile_model(str(TEXT_ENCODER_PATH), \"CPU\")\n",
    "text_input = text_model.input(0)\n",
    "text_output = text_model.output(0)\n",
    "print(f\"  Input shape: {text_input.partial_shape}\")\n",
    "print(f\"  Output shape: {text_output.partial_shape}\")\n",
    "\n",
    "print(\"\\n✓ OpenVINO models loaded on Intel CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06eaaf",
   "metadata": {},
   "source": [
    "## 5. Define Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"✓ Image preprocessing defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b055e1",
   "metadata": {},
   "source": [
    "## 6. Embedding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3621b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image_path):\n",
    "    \"\"\"Generate embedding for a Fashion MNIST image using OpenVINO\"\"\"\n",
    "    # Load and preprocess image (Fashion MNIST is grayscale)\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = image.convert('RGB')  # Convert to 3-channel for model compatibility\n",
    "    image_tensor = preprocess(image).unsqueeze(0)\n",
    "    \n",
    "    # Run inference\n",
    "    result = image_model([image_tensor.numpy()])[image_output]\n",
    "    embedding = result[0]\n",
    "    \n",
    "    # Normalize\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    return embedding.astype('float32')\n",
    "\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    \"\"\"Generate embedding for text using OpenVINO\"\"\"\n",
    "    # Encode text\n",
    "    text_indices = vocab.encode(text, MAX_TEXT_LENGTH)\n",
    "    text_tensor = np.array([text_indices], dtype=np.int64)\n",
    "    \n",
    "    # Run inference\n",
    "    result = text_model([text_tensor])[text_output]\n",
    "    embedding = result[0]\n",
    "    \n",
    "    # Normalize\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    return embedding.astype('float32')\n",
    "\n",
    "print(\"✓ Embedding functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b54ce",
   "metadata": {},
   "source": [
    "## 7. Build or Load Embeddings Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33af5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDINGS_FILE.exists() and METADATA_FILE.exists():\n",
    "    print(\"✓ Loading existing embeddings database...\")\n",
    "    \n",
    "    embeddings = np.load(EMBEDDINGS_FILE)\n",
    "    with open(METADATA_FILE, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    image_paths = metadata['image_paths']\n",
    "    \n",
    "    print(f\"✓ Loaded {len(embeddings)} embeddings\")\n",
    "    print(f\"  Embedding shape: {embeddings.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Building embeddings database from scratch...\")\n",
    "    \n",
    "    # Collect all images\n",
    "    image_paths = []\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "    \n",
    "    for class_name in CLASSES:\n",
    "        class_dir = DATASET_PATH / class_name\n",
    "        if class_dir.exists():\n",
    "            for img_path in class_dir.iterdir():\n",
    "                if img_path.suffix.lower() in valid_extensions:\n",
    "                    image_paths.append(str(img_path))\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = []\n",
    "    valid_paths = []\n",
    "    \n",
    "    print(\"Generating embeddings...\")\n",
    "    for img_path in tqdm(image_paths):\n",
    "        try:\n",
    "            embedding = get_image_embedding(img_path)\n",
    "            embeddings.append(embedding)\n",
    "            valid_paths.append(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    embeddings = np.array(embeddings).astype('float32')\n",
    "    image_paths = valid_paths\n",
    "    \n",
    "    print(f\"Generated {len(embeddings)} embeddings\")\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(EMBEDDINGS_FILE, embeddings)\n",
    "    print(f\"✓ Embeddings saved to {EMBEDDINGS_FILE}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'image_paths': image_paths,\n",
    "        'total_images': len(image_paths),\n",
    "        'embedding_dim': embeddings.shape[1]\n",
    "    }\n",
    "    with open(METADATA_FILE, 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    print(f\"✓ Metadata saved to {METADATA_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdb818",
   "metadata": {},
   "source": [
    "## 8. Build or Load FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAISS_INDEX_FILE.exists():\n",
    "    print(\"✓ Loading existing FAISS index...\")\n",
    "    index = faiss.read_index(str(FAISS_INDEX_FILE))\n",
    "    print(f\"✓ FAISS index loaded with {index.ntotal} vectors\")\n",
    "else:\n",
    "    print(\"Building FAISS index...\")\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)  # Inner product (cosine similarity)\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    # Save index\n",
    "    faiss.write_index(index, str(FAISS_INDEX_FILE))\n",
    "    print(f\"✓ FAISS index built with {index.ntotal} vectors\")\n",
    "    print(f\"✓ Index saved to {FAISS_INDEX_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61017d9",
   "metadata": {},
   "source": [
    "## 9. Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afda8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_images(query_embedding, top_k=TOP_K):\n",
    "    \"\"\"Search for similar images using FAISS\"\"\"\n",
    "    query_embedding = query_embedding.reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        results.append({\n",
    "            'path': image_paths[idx],\n",
    "            'similarity': float(dist),\n",
    "            'class': Path(image_paths[idx]).parent.name\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Search function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac683aa",
   "metadata": {},
   "source": [
    "## 10. Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fcd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results, query_info=None):\n",
    "    \"\"\"Display search results in a grid\"\"\"\n",
    "    n_results = len(results)\n",
    "    cols = 5\n",
    "    rows = (n_results + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    if n_results == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        img = Image.open(result['path'])\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        title = f\"{result['class']}\\nSim: {result['similarity']:.3f}\"\n",
    "        axes[idx].set_title(title, fontsize=10)\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(n_results, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    if query_info:\n",
    "        fig.suptitle(f\"Query: {query_info}\", fontsize=14, fontweight='bold', y=1.00)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ Visualization function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad6565",
   "metadata": {},
   "source": [
    "## 11. Image-Based Search Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Search by image from Fashion MNIST\n",
    "query_image_path = r\"e:\\Projects\\AI Based\\RecTrio\\datasets\\fashion_mnist\\processed\\train\\tshirt\\00001.png\"\n",
    "\n",
    "print(f\"Searching for fashion items similar to: {Path(query_image_path).name}\")\n",
    "\n",
    "# Get embedding\n",
    "query_embedding = get_image_embedding(query_image_path)\n",
    "\n",
    "# Search\n",
    "results = search_similar_images(query_embedding, top_k=10)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTop {len(results)} similar fashion items:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. [{result['class']}] {Path(result['path']).name} - Similarity: {result['similarity']:.4f}\")\n",
    "\n",
    "display_results(results, query_info=f\"Image: {Path(query_image_path).name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e299a",
   "metadata": {},
   "source": [
    "## 12. Text-Based Search Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Search by text\n",
    "query_text = \"a casual t-shirt with short sleeves\"\n",
    "\n",
    "print(f\"Searching for: '{query_text}'\")\n",
    "\n",
    "# Get embedding\n",
    "query_embedding = get_text_embedding(query_text)\n",
    "\n",
    "# Search\n",
    "results = search_similar_images(query_embedding, top_k=10)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTop {len(results)} matching fashion items:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. [{result['class']}] {Path(result['path']).name} - Similarity: {result['similarity']:.4f}\")\n",
    "\n",
    "display_results(results, query_info=f\"Text: '{query_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14335626",
   "metadata": {},
   "source": [
    "## 13. Try Different Text Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6de05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different fashion descriptions\n",
    "test_queries = [\n",
    "    \"a warm winter coat with long sleeves\",\n",
    "    \"comfortable running sneakers\",\n",
    "    \"an elegant dress for women\",\n",
    "    \"casual trousers for everyday wear\",\n",
    "    \"open-toed summer sandals\"\n",
    "]\n",
    "\n",
    "for query_text in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print('='*60)\n",
    "    \n",
    "    query_embedding = get_text_embedding(query_text)\n",
    "    results = search_similar_images(query_embedding, top_k=5)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. [{result['class']}] {Path(result['path']).name} - Sim: {result['similarity']:.4f}\")\n",
    "    \n",
    "    display_results(results[:5], query_info=f\"Text: '{query_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc54ee7",
   "metadata": {},
   "source": [
    "## 14. Interactive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_search():\n",
    "    \"\"\"Interactive search interface\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MULTIMODAL IMAGE SEARCH\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Choose search type:\")\n",
    "    print(\"1. Search by image\")\n",
    "    print(\"2. Search by text description\")\n",
    "    \n",
    "    choice = input(\"\\nEnter choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        img_path = input(\"Enter image path: \").strip()\n",
    "        if not Path(img_path).exists():\n",
    "            print(\"❌ Image not found!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nSearching for images similar to: {Path(img_path).name}\")\n",
    "        query_embedding = get_image_embedding(img_path)\n",
    "        results = search_similar_images(query_embedding, top_k=10)\n",
    "        \n",
    "        print(f\"\\nTop {len(results)} results:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"{i}. [{result['class']}] {Path(result['path']).name} - Sim: {result['similarity']:.4f}\")\n",
    "        \n",
    "        display_results(results, query_info=f\"Image: {Path(img_path).name}\")\n",
    "        \n",
    "    elif choice == \"2\":\n",
    "        text_query = input(\"Enter text description: \").strip()\n",
    "        if not text_query:\n",
    "            print(\"❌ Empty query!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nSearching for: '{text_query}'\")\n",
    "        query_embedding = get_text_embedding(text_query)\n",
    "        results = search_similar_images(query_embedding, top_k=10)\n",
    "        \n",
    "        print(f\"\\nTop {len(results)} results:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"{i}. [{result['class']}] {Path(result['path']).name} - Sim: {result['similarity']:.4f}\")\n",
    "        \n",
    "        display_results(results, query_info=f\"Text: '{text_query}'\")\n",
    "    else:\n",
    "        print(\"❌ Invalid choice!\")\n",
    "\n",
    "# Run interactive search\n",
    "interactive_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5adeb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What This Notebook Does:\n",
    "1. ✅ Loads Intel CPU-optimized OpenVINO models\n",
    "2. ✅ Generates/loads embeddings for all Fashion MNIST images\n",
    "3. ✅ Builds FAISS index for fast similarity search\n",
    "4. ✅ Supports **image query** → get similar fashion items\n",
    "5. ✅ Supports **text query** → get matching fashion items\n",
    "\n",
    "### Dataset:\n",
    "- **Fashion MNIST**: 60,000 training images across 10 fashion categories\n",
    "- **Categories**: T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
    "- **Image Format**: Grayscale (converted to 3-channel for model)\n",
    "\n",
    "### Model Architecture:\n",
    "- **Image Encoder**: Custom CNN (Intel CPU optimized, grayscale support)\n",
    "- **Text Encoder**: LSTM-based encoder (Intel CPU optimized)\n",
    "- **Shared Embedding Space**: 256-dimensional\n",
    "\n",
    "### Performance:\n",
    "- Fast inference on Intel CPUs using OpenVINO\n",
    "- Efficient similarity search with FAISS\n",
    "- Supports both modalities seamlessly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
